<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>翻譯 Sam Altman 於 2023 年 03 月的 abcNEWS 專訪 | 最近學什麼</title>
<meta name=keywords content><meta name=description content="本文翻譯自 abcNEWS 於 2023/03/17 發布的文章（ 原文連結 ）
Sam Altman 承認 AI 存在風險，也對此有所擔心。 OpenAI 的 CEO Sam Altman 認為，人工智慧技術將徹底改變我們熟知的社會。 他揭示，儘管這項技術有真實的風險，但它也有可能變成人類歷史上最偉大的創新，進一步改善我們的生活。
OpenAI 的 CEO Sam Altman 表示：「我們需要對這件事保持警惕，我認為人們會對我們對此有些擔心感到安心。」
Altman 接受 ABC News 的首席商業、科技和經濟通訊記者 Rebecca Jarvis 的專訪，並對最新的 AI 語言模式 GPT-4 進行了深入討論。 他強烈認為，應該讓監管機構和社會公眾參與對話生成式預訓練模型的導入，並透過社區回饋來尋找防止這項技術帶來的可能負面影響的方法。 他補充說，他和政府官員有定期的接觸。
ChatGPT 是一款 AI 語言模型，其中的「GPT」表示生成式預訓練 Transformer。 這個應用程式發布不久以來，已經被譽為史上成長最快的消費性應用程式之一。 在短短幾個月內，它的月活躍用戶已超過 1 億。 相比之下，據瑞銀的一項研究顯示，TikTok 花了九個月才達到這個數量的用戶，而 Instagram 則花了近三年的時間。
儘管 GPT-4 還不是完美，但根據 Altman 的說法，它在統一律師考試中的表現位於前 10%，在美國大學入學考試的數學部分得到了接近滿分的成績，並且現在可以在多種編程語言中 熟練地撰寫電腦程式碼。
開發 GPT-4 只是 OpenAI 為達成建立通用人工智能（AGI，Artificial General Intelligence）目標所跨出的一步。 當人工智慧系統在各類任務中普遍超越人類智慧，我們就可以說 AI 已經達到了一個重要的里程碑。"><meta name=author content><link rel=canonical href=https://blog.nien.cc/translations/translation-sam-altman-2023-march-abcnews-interview/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://blog.nien.cc/note_64x64.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.nien.cc/note_16x16.ico><link rel=icon type=image/png sizes=32x32 href=https://blog.nien.cc/note_32x32.ico><link rel=apple-touch-icon href=https://blog.nien.cc/apple-touch-icon.png><link rel=mask-icon href=https://blog.nien.cc/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="翻譯 Sam Altman 於 2023 年 03 月的 abcNEWS 專訪"><meta property="og:description" content="本文翻譯自 abcNEWS 於 2023/03/17 發布的文章（ 原文連結 ）
Sam Altman 承認 AI 存在風險，也對此有所擔心。 OpenAI 的 CEO Sam Altman 認為，人工智慧技術將徹底改變我們熟知的社會。 他揭示，儘管這項技術有真實的風險，但它也有可能變成人類歷史上最偉大的創新，進一步改善我們的生活。
OpenAI 的 CEO Sam Altman 表示：「我們需要對這件事保持警惕，我認為人們會對我們對此有些擔心感到安心。」
Altman 接受 ABC News 的首席商業、科技和經濟通訊記者 Rebecca Jarvis 的專訪，並對最新的 AI 語言模式 GPT-4 進行了深入討論。 他強烈認為，應該讓監管機構和社會公眾參與對話生成式預訓練模型的導入，並透過社區回饋來尋找防止這項技術帶來的可能負面影響的方法。 他補充說，他和政府官員有定期的接觸。
ChatGPT 是一款 AI 語言模型，其中的「GPT」表示生成式預訓練 Transformer。 這個應用程式發布不久以來，已經被譽為史上成長最快的消費性應用程式之一。 在短短幾個月內，它的月活躍用戶已超過 1 億。 相比之下，據瑞銀的一項研究顯示，TikTok 花了九個月才達到這個數量的用戶，而 Instagram 則花了近三年的時間。
儘管 GPT-4 還不是完美，但根據 Altman 的說法，它在統一律師考試中的表現位於前 10%，在美國大學入學考試的數學部分得到了接近滿分的成績，並且現在可以在多種編程語言中 熟練地撰寫電腦程式碼。
開發 GPT-4 只是 OpenAI 為達成建立通用人工智能（AGI，Artificial General Intelligence）目標所跨出的一步。 當人工智慧系統在各類任務中普遍超越人類智慧，我們就可以說 AI 已經達到了一個重要的里程碑。"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.nien.cc/translations/translation-sam-altman-2023-march-abcnews-interview/"><meta property="og:image" content="https://blog.nien.cc/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="translations"><meta property="article:published_time" content="2024-02-23T18:00:00+08:00"><meta property="article:modified_time" content="2024-02-23T18:00:00+08:00"><meta property="og:site_name" content="最近學什麼"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.nien.cc/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="翻譯 Sam Altman 於 2023 年 03 月的 abcNEWS 專訪"><meta name=twitter:description content="本文翻譯自 abcNEWS 於 2023/03/17 發布的文章（ 原文連結 ）
Sam Altman 承認 AI 存在風險，也對此有所擔心。 OpenAI 的 CEO Sam Altman 認為，人工智慧技術將徹底改變我們熟知的社會。 他揭示，儘管這項技術有真實的風險，但它也有可能變成人類歷史上最偉大的創新，進一步改善我們的生活。
OpenAI 的 CEO Sam Altman 表示：「我們需要對這件事保持警惕，我認為人們會對我們對此有些擔心感到安心。」
Altman 接受 ABC News 的首席商業、科技和經濟通訊記者 Rebecca Jarvis 的專訪，並對最新的 AI 語言模式 GPT-4 進行了深入討論。 他強烈認為，應該讓監管機構和社會公眾參與對話生成式預訓練模型的導入，並透過社區回饋來尋找防止這項技術帶來的可能負面影響的方法。 他補充說，他和政府官員有定期的接觸。
ChatGPT 是一款 AI 語言模型，其中的「GPT」表示生成式預訓練 Transformer。 這個應用程式發布不久以來，已經被譽為史上成長最快的消費性應用程式之一。 在短短幾個月內，它的月活躍用戶已超過 1 億。 相比之下，據瑞銀的一項研究顯示，TikTok 花了九個月才達到這個數量的用戶，而 Instagram 則花了近三年的時間。
儘管 GPT-4 還不是完美，但根據 Altman 的說法，它在統一律師考試中的表現位於前 10%，在美國大學入學考試的數學部分得到了接近滿分的成績，並且現在可以在多種編程語言中 熟練地撰寫電腦程式碼。
開發 GPT-4 只是 OpenAI 為達成建立通用人工智能（AGI，Artificial General Intelligence）目標所跨出的一步。 當人工智慧系統在各類任務中普遍超越人類智慧，我們就可以說 AI 已經達到了一個重要的里程碑。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Translations","item":"https://blog.nien.cc/translations/"},{"@type":"ListItem","position":2,"name":"翻譯 Sam Altman 於 2023 年 03 月的 abcNEWS 專訪","item":"https://blog.nien.cc/translations/translation-sam-altman-2023-march-abcnews-interview/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"翻譯 Sam Altman 於 2023 年 03 月的 abcNEWS 專訪","name":"翻譯 Sam Altman 於 2023 年 03 月的 abcNEWS 專訪","description":"本文翻譯自 abcNEWS 於 2023/03/17 發布的文章（ 原文連結 ）\nSam Altman 承認 AI 存在風險，也對此有所擔心。 OpenAI 的 CEO Sam Altman 認為，人工智慧技術將徹底改變我們熟知的社會。 他揭示，儘管這項技術有真實的風險，但它也有可能變成人類歷史上最偉大的創新，進一步改善我們的生活。\nOpenAI 的 CEO Sam Altman 表示：「我們需要對這件事保持警惕，我認為人們會對我們對此有些擔心感到安心。」\nAltman 接受 ABC News 的首席商業、科技和經濟通訊記者 Rebecca Jarvis 的專訪，並對最新的 AI 語言模式 GPT-4 進行了深入討論。 他強烈認為，應該讓監管機構和社會公眾參與對話生成式預訓練模型的導入，並透過社區回饋來尋找防止這項技術帶來的可能負面影響的方法。 他補充說，他和政府官員有定期的接觸。\nChatGPT 是一款 AI 語言模型，其中的「GPT」表示生成式預訓練 Transformer。 這個應用程式發布不久以來，已經被譽為史上成長最快的消費性應用程式之一。 在短短幾個月內，它的月活躍用戶已超過 1 億。 相比之下，據瑞銀的一項研究顯示，TikTok 花了九個月才達到這個數量的用戶，而 Instagram 則花了近三年的時間。\n儘管 GPT-4 還不是完美，但根據 Altman 的說法，它在統一律師考試中的表現位於前 10%，在美國大學入學考試的數學部分得到了接近滿分的成績，並且現在可以在多種編程語言中 熟練地撰寫電腦程式碼。\n開發 GPT-4 只是 OpenAI 為達成建立通用人工智能（AGI，Artificial General Intelligence）目標所跨出的一步。 當人工智慧系統在各類任務中普遍超越人類智慧，我們就可以說 AI 已經達到了一個重要的里程碑。","keywords":[],"articleBody":" 本文翻譯自 abcNEWS 於 2023/03/17 發布的文章（ 原文連結 ）\nSam Altman 承認 AI 存在風險，也對此有所擔心。 OpenAI 的 CEO Sam Altman 認為，人工智慧技術將徹底改變我們熟知的社會。 他揭示，儘管這項技術有真實的風險，但它也有可能變成人類歷史上最偉大的創新，進一步改善我們的生活。\nOpenAI 的 CEO Sam Altman 表示：「我們需要對這件事保持警惕，我認為人們會對我們對此有些擔心感到安心。」\nAltman 接受 ABC News 的首席商業、科技和經濟通訊記者 Rebecca Jarvis 的專訪，並對最新的 AI 語言模式 GPT-4 進行了深入討論。 他強烈認為，應該讓監管機構和社會公眾參與對話生成式預訓練模型的導入，並透過社區回饋來尋找防止這項技術帶來的可能負面影響的方法。 他補充說，他和政府官員有定期的接觸。\nChatGPT 是一款 AI 語言模型，其中的「GPT」表示生成式預訓練 Transformer。 這個應用程式發布不久以來，已經被譽為史上成長最快的消費性應用程式之一。 在短短幾個月內，它的月活躍用戶已超過 1 億。 相比之下，據瑞銀的一項研究顯示，TikTok 花了九個月才達到這個數量的用戶，而 Instagram 則花了近三年的時間。\n儘管 GPT-4 還不是完美，但根據 Altman 的說法，它在統一律師考試中的表現位於前 10%，在美國大學入學考試的數學部分得到了接近滿分的成績，並且現在可以在多種編程語言中 熟練地撰寫電腦程式碼。\n開發 GPT-4 只是 OpenAI 為達成建立通用人工智能（AGI，Artificial General Intelligence）目標所跨出的一步。 當人工智慧系統在各類任務中普遍超越人類智慧，我們就可以說 AI 已經達到了一個重要的里程碑。\n儘管 Altman 為他的產品的成就感到高興，他也坦承 AI 的潛在危險讓他夜裡難以入睡。\nAltman 表示「我特別擔心這些模型可能被用於大規模散佈虛假信息 … 隨著它們在撰寫電腦程式碼方面的進步，它們也可能被用來進行針對性的網路攻擊。」\n不同於科幻電影中常見的恐懼，Altman 並不擔心 AI 模型會自主地操控事物，甚至策劃統治世界。\n「AI Agent 是需要等待某人輸入指令的，這個工具完全在人類的操控之下。」然而，他表達出他對人類控制權可能被濫用的擔憂。他補充「也許會有其他的開發者，他們設定的安全限制不如我們嚴謹 … 我認為，社會必須在有限的時間內找出如何應對此類情況、實施監管並找出解決方案。」\n2017 年，在開學第一天，俄羅斯總統普丁告訴學生，誰能掌握 AI 的領導地位，誰就有可能「主宰世界」。\n對此，Altman 表示「這確實引來了深思。但我所希望看到的是，我們可以逐步發展出更強大的知識體系，使我們能以獨特的方式應用於日常生活和經濟活動中，並成為以人類意識為導向的強化工具。」\n對虛假資訊的關注與 AI 的挑戰 OpenAI 的新言語模型 GPT-4 在先前版本的基礎上有了重大的進步，甚至能以圖像作為輸入進行處理。在展示中，GPT-4 展現了能描述冰箱內的物品、解答謎語，甚至澄清網路迷因（Internet meme）背後隱含的含義。\n雖然這項功能目前只對少數用戶開放，也包含一群作為測試人員的視障者群體，然而，如同 ChatGPT 這種 AI 語言模型，同樣存在著信息不準確的問題：該程序可能會給用戶提供事實並非準確的信息。\nAltman 說「我特別想要提醒大家的就是這個幻覺問題 … 該模型可能會非常有自信地宣稱一些根本是捏造的事，宛如它們就是事實一般。」\n該模型之所以會出現這個問題，部分原因是因為 OpenAI 說，該模型並非只依靠記憶，而是採用推論的方式。\nOpenAI 的首席技術官 Mira Murati 在接受 ABC 新聞訪問時，表示「從 GPT-3.5 升級到 GPT-4，最明顯的變化之一，就是模型出現了更強大的推論能力。」\nMurati 提到，「我們的目標是透過預測下一個詞彙來更深入地理解語言。我們希望這些模型能更好地像我們一樣看待和理解世界。」\nAltman 指出「我們創造的模型更像是推理引擎，而並非一個純粹的事實庫。 … 雖然它們確實能扮演事實庫的角色，但那並不是它們的特長，我們希望讓他們更擅長於推理而非僅局限於記憶。」\nAltman 和他的團隊希望模型在未來能逐漸演變為一個推理機制，最終能利用互聯網和他們的演繹推理能力來區分事實與虛構。根據 OpenAI 的說法，GPT-4 比先前的版本在產生準確的信息上更具競爭力，準確度提高了 40%。即便如此，Altman 仍建議不應把這個系統當作主要的準確資訊來源，並鼓勵用戶對結果進行雙重檢查。\n預防惡意行為的策略 我們都深知 AI 語言模型，例如 ChatGPT，內含的資訊種類可能會引起注意，人們可能會擔心他是否可能教導使用者製造危險物品。然而，如 Altman 所說，這種擔憂是不需要的，因為在 ChatGPT 中已經加入了保護措施。\nAltman 表示「但是他必須擔心的是，我們不一定是這項技術的唯一創造者，必然會有其他人可能不會像我們一樣對其設立一些安全限制。」\n不過毫無疑問，我們已經當機立斷地選擇了幾種適合的方法和安全防禦手段，來降低可能的 AI 風險，如同 Altman 所述。其中一個策略是在相對風險較低的情況下，先讓大眾嘗試使用 ChatGPT ，觀察使用情況並從中學習。\nMurati 分享「ChatGPT 目前對大眾開放，這主要是因為我們希望能夠收集更多的用戶回饋。 … 當大眾開始使用 OpenAI 應用程式時，我們能更有效地識別出應加強的安全措施。」\nMurati 繼續解釋「了解大眾如何使用 ChatGPT，以及他們遇到的困難與挑戰，這些都使我們能夠直接參與並提昇這項技術。」Altman 同樣認為給公眾機會與每一版的 ChatGPT 互動是非常重要的。\nAltman 表示「如果我們獨於自身的小實驗室內秘密進行開發，直到製造出 GPT-7，然後直接把它推向世界的話 … 我認為這樣可能會有更多的負面影響。因為大家是需要時間去接受、應對，更要適應這項技術，以及理解其風險和可能的應對方案。」\n關於可能的爭議性內容，Altman 提及 OpenAI 有一個團隊是由專家所組成，負責制定政策，決定 ChatGPT 中該有哪些資訊內容，以及哪些內容可以提供給使用者。\nAltman 補充道「我們正持續與各政策和安全專家討論、進行系統審查，全力解決問題，確保能推出一個最安全、最有效的方案。 … 我們的公司在剛開始的時候可能並不會做得完美，但在較低風險的狀態下學習並探索邊界確實非常重要。」\n人工智慧會取代我們的工作嗎？ 一個始終困擾我們的問題是人工智能將帶來怎樣的變革。其中一種普遍關注的焦點是這項新技術是否會取代我們的工作。Altman 承認，人工智能確實有可能在不久的將來取代一部分的工作，而這種改變可能快得讓人們難以適應的。\n他表示「在過去幾代人的時間裡，我們已經證明人類能夠以驚人的力度來適應科技的重大變革。但如果這種變革在短短幾年之內就發生了，這可能會引起一些難以預料的問題 … 這是我們最應該擔憂的部分。」\n然而，他也富有鼓舞人心的提醒我們，要把 ChatGPT 視為一個工具，而不是將我們取代的對手。他說「人的創造力是無窮無盡的，我們將會創造出新的工作機會，也會找到新的事物去做。」\n從 Altman 的觀點來看，將 ChatGPT 作為工具使用的好處遠遠超過其風險。他相信，這樣的工具能夠提供個人化的學習體驗，對每個人的教育都非常有益。\n他說「我們每個人都可以提供一個高度個性化的出色學習工具，這將有助於我們的學習與成長。同時，我們還可以向每個人給予超越當今醫療水平的醫療意見。」\n無論如何，人工智能的未來或許充滿未知，但只要我們能適時適當地調整與適應，就有望從中獲得巨大的收益。\nChatGPT 作為「Co-pilot 共同助手」的角色 在這裡，「Co-pilot 共同助手」這個詞像是一面鏡子，為我們生動描繪出 ChatGPT 的角色，讓我們更能直觀地理解其當下的運作狀況。在教育領域，聊天生成模型（ChatGPT）的應用已引起熱烈討論。部分學生甚至把 ChatGPT 當作權威參考，試圖藉此捷足先登。對於這種現象，教育者的觀點不盡相同。有些人認為這種方式其實是教學的一種進化，能為學生提供更多學習機會；然而，也有人擔心這會阻礙學生的主動學習精神。\n「教育的變革已經在我們面前展開，然而，這與科技的進步是密不可分的，這已經不是什麼新鮮事」Altman 表示，並指出，學生將能接觸到更加超越傳統課堂的課程和學習方式，他特別期待能夠給予每位學生更具個人化與深度的學習體驗。\n在大多數領域裡，Altman 及其團隊抱著這樣的願景：讓使用者視 ChatGPT 為一位「共同助手」，如同一位能夠協助你撰寫複雜代碼或協助解決各種問題的終極助理。\n「我們對任何領域都抱持著這樣的盼望，即透過 AI 來提高我們的生活品質，例如我們的生活水平。」Altman 表示。「同時，我們也期待有些今天我們甚至無法想像的新事物的出現。這就是我們的終極目標所在。」\n","wordCount":"218","inLanguage":"en","datePublished":"2024-02-23T18:00:00+08:00","dateModified":"2024-02-23T18:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.nien.cc/translations/translation-sam-altman-2023-march-abcnews-interview/"},"publisher":{"@type":"Organization","name":"最近學什麼","logo":{"@type":"ImageObject","url":"https://blog.nien.cc/note_64x64.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.nien.cc/ accesskey=h title="最近學什麼 (Alt + H)"><img src=https://blog.nien.cc/images/note.png alt aria-label=logo height=35>最近學什麼</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.nien.cc/posts/ title=原創><span>原創</span></a></li><li><a href=https://blog.nien.cc/translations/ title=翻譯><span>翻譯</span></a></li><li><a href=https://blog.nien.cc/notes/ title=筆記><span>筆記</span></a></li><li><a href=https://blog.nien.cc/slides/ title=簡報><span>簡報</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">翻譯 Sam Altman 於 2023 年 03 月的 abcNEWS 專訪</h1><div class=post-meta><span title='2024-02-23 18:00:00 +0800 +0800'>February 23, 2024</span></div></header><div class=post-content><p><img loading=lazy src=/images/translation-sam-altman-2023-march-abcnews-interview.webp alt="翻譯 Sam Altman 於 2023 年 03 月的 abcNEWS 專訪"></p><blockquote><p>本文翻譯自 abcNEWS 於 2023/03/17 發布的文章（
<a href="https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122" target=_blank rel=noopener>原文連結</a>
）</p></blockquote><h2 id=sam-altman-承認-ai-存在風險也對此有所擔心>Sam Altman 承認 AI 存在風險，也對此有所擔心。<a hidden class=anchor aria-hidden=true href=#sam-altman-承認-ai-存在風險也對此有所擔心>#</a></h2><p>OpenAI 的 CEO Sam Altman 認為，人工智慧技術將徹底改變我們熟知的社會。 他揭示，儘管這項技術有真實的風險，但它也有可能變成人類歷史上最偉大的創新，進一步改善我們的生活。</p><p>OpenAI 的 CEO Sam Altman 表示：「我們需要對這件事保持警惕，我認為人們會對我們對此有些擔心感到安心。」</p><p>Altman 接受 ABC News 的首席商業、科技和經濟通訊記者 Rebecca Jarvis 的專訪，並對最新的 AI 語言模式 GPT-4 進行了深入討論。 他強烈認為，應該讓監管機構和社會公眾參與對話生成式預訓練模型的導入，並透過社區回饋來尋找防止這項技術帶來的可能負面影響的方法。 他補充說，他和政府官員有定期的接觸。</p><p>ChatGPT 是一款 AI 語言模型，其中的「GPT」表示生成式預訓練 Transformer。 這個應用程式發布不久以來，已經被譽為史上成長最快的消費性應用程式之一。 在短短幾個月內，它的月活躍用戶已超過 1 億。 相比之下，據瑞銀的一項研究顯示，TikTok 花了九個月才達到這個數量的用戶，而 Instagram 則花了近三年的時間。</p><p>儘管 GPT-4 還不是完美，但根據 Altman 的說法，它在統一律師考試中的表現位於前 10%，在美國大學入學考試的數學部分得到了接近滿分的成績，並且現在可以在多種編程語言中 熟練地撰寫電腦程式碼。</p><p>開發 GPT-4 只是 OpenAI 為達成建立通用人工智能（AGI，Artificial General Intelligence）目標所跨出的一步。 當人工智慧系統在各類任務中普遍超越人類智慧，我們就可以說 AI 已經達到了一個重要的里程碑。</p><p>儘管 Altman 為他的產品的成就感到高興，他也坦承 AI 的潛在危險讓他夜裡難以入睡。</p><p>Altman 表示「我特別擔心這些模型可能被用於大規模散佈虛假信息 &mldr; 隨著它們在撰寫電腦程式碼方面的進步，它們也可能被用來進行針對性的網路攻擊。」</p><p>不同於科幻電影中常見的恐懼，Altman 並不擔心 AI 模型會自主地操控事物，甚至策劃統治世界。</p><p>「AI Agent 是需要等待某人輸入指令的，這個工具完全在人類的操控之下。」然而，他表達出他對人類控制權可能被濫用的擔憂。他補充「也許會有其他的開發者，他們設定的安全限制不如我們嚴謹 &mldr; 我認為，社會必須在有限的時間內找出如何應對此類情況、實施監管並找出解決方案。」</p><p>2017 年，在開學第一天，俄羅斯總統普丁告訴學生，誰能掌握 AI 的領導地位，誰就有可能「主宰世界」。</p><p>對此，Altman 表示「這確實引來了深思。但我所希望看到的是，我們可以逐步發展出更強大的知識體系，使我們能以獨特的方式應用於日常生活和經濟活動中，並成為以人類意識為導向的強化工具。」</p><h2 id=對虛假資訊的關注與-ai-的挑戰>對虛假資訊的關注與 AI 的挑戰<a hidden class=anchor aria-hidden=true href=#對虛假資訊的關注與-ai-的挑戰>#</a></h2><p>OpenAI 的新言語模型 GPT-4 在先前版本的基礎上有了重大的進步，甚至能以圖像作為輸入進行處理。在展示中，GPT-4 展現了能描述冰箱內的物品、解答謎語，甚至澄清網路迷因（Internet meme）背後隱含的含義。</p><p>雖然這項功能目前只對少數用戶開放，也包含一群作為測試人員的視障者群體，然而，如同 ChatGPT 這種 AI 語言模型，同樣存在著信息不準確的問題：該程序可能會給用戶提供事實並非準確的信息。</p><p>Altman 說「我特別想要提醒大家的就是這個幻覺問題 &mldr; 該模型可能會非常有自信地宣稱一些根本是捏造的事，宛如它們就是事實一般。」</p><p>該模型之所以會出現這個問題，部分原因是因為 OpenAI 說，該模型並非只依靠記憶，而是採用推論的方式。</p><p>OpenAI 的首席技術官 Mira Murati 在接受 ABC 新聞訪問時，表示「從 GPT-3.5 升級到 GPT-4，最明顯的變化之一，就是模型出現了更強大的推論能力。」</p><p>Murati 提到，「我們的目標是透過預測下一個詞彙來更深入地理解語言。我們希望這些模型能更好地像我們一樣看待和理解世界。」</p><p>Altman 指出「我們創造的模型更像是推理引擎，而並非一個純粹的事實庫。 &mldr; 雖然它們確實能扮演事實庫的角色，但那並不是它們的特長，我們希望讓他們更擅長於推理而非僅局限於記憶。」</p><p>Altman 和他的團隊希望模型在未來能逐漸演變為一個推理機制，最終能利用互聯網和他們的演繹推理能力來區分事實與虛構。根據 OpenAI 的說法，GPT-4 比先前的版本在產生準確的信息上更具競爭力，準確度提高了 40%。即便如此，Altman 仍建議不應把這個系統當作主要的準確資訊來源，並鼓勵用戶對結果進行雙重檢查。</p><h2 id=預防惡意行為的策略>預防惡意行為的策略<a hidden class=anchor aria-hidden=true href=#預防惡意行為的策略>#</a></h2><p>我們都深知 AI 語言模型，例如 ChatGPT，內含的資訊種類可能會引起注意，人們可能會擔心他是否可能教導使用者製造危險物品。然而，如 Altman 所說，這種擔憂是不需要的，因為在 ChatGPT 中已經加入了保護措施。</p><p>Altman 表示「但是他必須擔心的是，我們不一定是這項技術的唯一創造者，必然會有其他人可能不會像我們一樣對其設立一些安全限制。」</p><p>不過毫無疑問，我們已經當機立斷地選擇了幾種適合的方法和安全防禦手段，來降低可能的 AI 風險，如同 Altman 所述。其中一個策略是在相對風險較低的情況下，先讓大眾嘗試使用 ChatGPT ，觀察使用情況並從中學習。</p><p>Murati 分享「ChatGPT 目前對大眾開放，這主要是因為我們希望能夠收集更多的用戶回饋。 &mldr; 當大眾開始使用 OpenAI 應用程式時，我們能更有效地識別出應加強的安全措施。」</p><p>Murati 繼續解釋「了解大眾如何使用 ChatGPT，以及他們遇到的困難與挑戰，這些都使我們能夠直接參與並提昇這項技術。」Altman 同樣認為給公眾機會與每一版的 ChatGPT 互動是非常重要的。</p><p>Altman 表示「如果我們獨於自身的小實驗室內秘密進行開發，直到製造出 GPT-7，然後直接把它推向世界的話 &mldr; 我認為這樣可能會有更多的負面影響。因為大家是需要時間去接受、應對，更要適應這項技術，以及理解其風險和可能的應對方案。」</p><p>關於可能的爭議性內容，Altman 提及 OpenAI 有一個團隊是由專家所組成，負責制定政策，決定 ChatGPT 中該有哪些資訊內容，以及哪些內容可以提供給使用者。</p><p>Altman 補充道「我們正持續與各政策和安全專家討論、進行系統審查，全力解決問題，確保能推出一個最安全、最有效的方案。 &mldr; 我們的公司在剛開始的時候可能並不會做得完美，但在較低風險的狀態下學習並探索邊界確實非常重要。」</p><h2 id=人工智慧會取代我們的工作嗎>人工智慧會取代我們的工作嗎？<a hidden class=anchor aria-hidden=true href=#人工智慧會取代我們的工作嗎>#</a></h2><p>一個始終困擾我們的問題是人工智能將帶來怎樣的變革。其中一種普遍關注的焦點是這項新技術是否會取代我們的工作。Altman 承認，人工智能確實有可能在不久的將來取代一部分的工作，而這種改變可能快得讓人們難以適應的。</p><p>他表示「在過去幾代人的時間裡，我們已經證明人類能夠以驚人的力度來適應科技的重大變革。但如果這種變革在短短幾年之內就發生了，這可能會引起一些難以預料的問題 &mldr; 這是我們最應該擔憂的部分。」</p><p>然而，他也富有鼓舞人心的提醒我們，要把 ChatGPT 視為一個工具，而不是將我們取代的對手。他說「人的創造力是無窮無盡的，我們將會創造出新的工作機會，也會找到新的事物去做。」</p><p>從 Altman 的觀點來看，將 ChatGPT 作為工具使用的好處遠遠超過其風險。他相信，這樣的工具能夠提供個人化的學習體驗，對每個人的教育都非常有益。</p><p>他說「我們每個人都可以提供一個高度個性化的出色學習工具，這將有助於我們的學習與成長。同時，我們還可以向每個人給予超越當今醫療水平的醫療意見。」</p><p>無論如何，人工智能的未來或許充滿未知，但只要我們能適時適當地調整與適應，就有望從中獲得巨大的收益。</p><h2 id=chatgpt-作為co-pilot-共同助手的角色>ChatGPT 作為「Co-pilot 共同助手」的角色<a hidden class=anchor aria-hidden=true href=#chatgpt-作為co-pilot-共同助手的角色>#</a></h2><p>在這裡，「Co-pilot 共同助手」這個詞像是一面鏡子，為我們生動描繪出 ChatGPT 的角色，讓我們更能直觀地理解其當下的運作狀況。在教育領域，聊天生成模型（ChatGPT）的應用已引起熱烈討論。部分學生甚至把 ChatGPT 當作權威參考，試圖藉此捷足先登。對於這種現象，教育者的觀點不盡相同。有些人認為這種方式其實是教學的一種進化，能為學生提供更多學習機會；然而，也有人擔心這會阻礙學生的主動學習精神。</p><p>「教育的變革已經在我們面前展開，然而，這與科技的進步是密不可分的，這已經不是什麼新鮮事」Altman 表示，並指出，學生將能接觸到更加超越傳統課堂的課程和學習方式，他特別期待能夠給予每位學生更具個人化與深度的學習體驗。</p><p>在大多數領域裡，Altman 及其團隊抱著這樣的願景：讓使用者視 ChatGPT 為一位「共同助手」，如同一位能夠協助你撰寫複雜代碼或協助解決各種問題的終極助理。</p><p>「我們對任何領域都抱持著這樣的盼望，即透過 AI 來提高我們的生活品質，例如我們的生活水平。」Altman 表示。「同時，我們也期待有些今天我們甚至無法想像的新事物的出現。這就是我們的終極目標所在。」</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://blog.nien.cc/>最近學什麼</a></span>
<span>contact@nien.cc
</span><span>/
</span><span><a href=https://www.flaticon.com/free-icons/note title="note icons">Note icons created by Freepik - Flaticon</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>